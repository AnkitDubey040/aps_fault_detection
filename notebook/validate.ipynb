{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will validate whether the train and test data is in accordance with the aps data csv file or not using the Scipy library for 2 sample hypothesis test .\n",
    "\n",
    "So we compare features of both the samples and if they have same distribution then we can say thet they are okay to go . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "sample1 = stats.uniform.rvs(size = 100 , random_state = rng)\n",
    "sample2 = stats.norm.rvs(size = 110,random_state=rng)\n",
    "response = stats.ks_2samp(sample1,sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9839344857931964e-16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since p-value is very small we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anamoly in dataset :\n",
    "1. High Null values \n",
    "2. Missing Columns\n",
    "3. Very High Outliers\n",
    "4. In categorical Columns if we get a new category in train or test that was not in original dataset\n",
    "\n",
    "### Drifts in ML:\n",
    "\n",
    "1. Covariate shift: distribution of input features changes.\n",
    "2. Concept drift: the relationship between the target variable and input features changes.\n",
    "3. Model decay: drop in model performance due to drift.\n",
    "4. Data drift: any distributional change. This is sometimes used instead to refer to covariate shift specifically.\n",
    "5. The other terms (distribution shift, dataset shift) can typically refer to any of the concepts above or a combination of them.\n",
    "6. Target drift : The the output of target column changes during validation part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"/config/workspace/artifact/122122_123318/data_ingestion/dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns with more 5 of null values than the threshold\n",
    "drop_column_names = []\n",
    "\n",
    "for column_name,missing_percentage in zip((df.isnull().sum()/df.shape[0]).index   ,   (df.isnull().sum()/df.shape[0]).values):\n",
    "    #print(column_name , missing_percentage*100)\n",
    "    if missing_percentage >0.3:\n",
    "        drop_column_names.append(column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab_000',\n",
       " 'bk_000',\n",
       " 'bl_000',\n",
       " 'bm_000',\n",
       " 'bn_000',\n",
       " 'bo_000',\n",
       " 'bp_000',\n",
       " 'bq_000',\n",
       " 'br_000',\n",
       " 'cr_000']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ab_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000',\n",
       "       'bq_000', 'br_000', 'cr_000'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_report = df.isna().sum()/df.shape[0]\n",
    "null_report[null_report>0.3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[:,[0]].drop(\"class\",axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "2 5\n",
      "3 6\n",
      "4 7\n"
     ]
    }
   ],
   "source": [
    "l1=[1,2,3,4]\n",
    "l2=[4,5,6,7]\n",
    "\n",
    "for l1_val,l2_val in zip(l1,l2):\n",
    "    print(l1_val,l2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
